--- 
title: "Hacking for Social Scientists"
subtitle: "A Guide to Programming With Data"
author: "Matthias Bannert"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
css: ["license.css"]
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "The vast majority of data has been created within the last decade. In turn many fields of research are confronted with an unprecented wealth of data. The sheer amount of information but also the complexity of modern datasets continues to point researchers to programming approaches who had not considered programming to process data so far. Hacking for Social Sciences and Humanities"
---

> "There two things users hate,
> *change*, and the way things are."
> `r tufte::quote_footer('--- \\@TheWierdWorld (ShowerThoughts Twitter Account)')`

# Preface

The vast majority of data has been created within the last decade. In turn many fields of research are confronted with an unprecented wealth of data. The sheer amount of information but also the complexity of modern datasets continues to point a kind researcher to programming approaches who had not considered programming to process data so far. Hacking for Social Sciences and Humanities aims to give a big picture overview and starting point to reach what the open source software community calls a 'software carpentry' level. Also, this book argues a solid software carpentry skill level is totally in reach for most researchers. And most importantly, investing is worth the effort: being able to code leverages field specific expertise and fosters interdisciplinary collaboration as source code continues to become an important communication channel. 

# Introduction - The Choice that Doesn't Matter

The very first (and intimidating) choice a novice hacker faces is which is programming language to learn. Unfortunately the medium popularily summed up as the internet offers a lot of really really good advice on the matter. The problem is, however, that this advice does not necessarily agree which language is the best for research. In the realm of data science -- get accustomed to that label if you are a scientist who works with data -- the debate basically comes down to two languages: The R Language for Statistical Computing and Python. 

At least to me, there is only one valid advice: **It simply does NOT matter**. If you stick around in data science long enough you will eventually get in touch with both languages and in turn learn both. There is a huge overlap of what you can with both languages. R came out of the rather specific domain of statiscs 25+ years ago and made its way to a more general programming language thanks to 15K+ extension packages (and counting). Built by a mathmatician Python continues to be as general purpose as ever but got more scientific thanks to packages such as {pandas}, {sciPy} or {numPy}. As a result there is a huge overlap of what both languages can do and both will extend your horizon in unprecendented fashion if you did not use a full fledged programming language for your analysis before. 

But why is there such a heartfelt debate online, if it doesn't matter? Let's pick up a random argument from this debate: R is to set up and Python is better for machine learning. If you worked with Java or another environment that's rather tricky to get going, you are hardened and might not need or cherish easy onboarding. If you got frustrated before you even really started trying to reproduce a nifty machine learning blog post because you installed the wrong version of Python or didn't manage to make sense of virtualenv you might feel otherwise. 

The point is,  rest assured, if you just start doing analytics using a programming languages both languages are guaranteed to carry you a long way. There is no way to tell for sure which one will be the more dominant language in 10 years from now or whether both still be around holding their ground the way they do now. But once you reached a decent software carpentry level in either language it will help you a lot learning the other. If your peers work with R, start with R, if your close community
works with Python, start with Python. If you are in for the longer run either language will help you understand the concepts and ideas of programming with data. Trust me, there will be a natural opportunity to get to know the other. 


## Why Would Social Scientists Want to Code?

First of all, because everybody and their grandmothers seem to do it. Statistical computing continues to be on the rise in many branches of social sciences. 



<!-- The below graph shows monthly accumulated extension package downloads for the R Language of Statistical Computing grouped by fields of research^[proxied this and that].
Econometrics, Psychometrics, National Language Processing, Official Statistics, Social Sciences

```{r, eval=TRUE}
# add CRAN TASK VIEW Download 
# Statistics graph here
rnorm(10)
```

-->

Second because it's reproducible. Code has become a tremendous communication channel. Your web scraper does not work? 
Instead of reaching out in a clumsy but wordy cry for help, posting what you tried to far described by source code will often get you good answers within hours on platforms like [Stackoverflow](https://stackoverflow.com) or [Crossvalidated](https://crossvalidated.com). Or imagine feature requests, after a little code ping pong with the package author your wish eventually becomes clearer. Let alone chats with colleagues and co-authors. Sharing code just works. 
Academic journals have found out, too in the meantime. Many outlets require you to make the data and source code behind your work available. [Social Science Data Editors](https://social-science-data-editors.github.io/guidance/template-README.html) is a bleeding edge project at the time of reading this, but is already referred to by top notch journals of the profession like American Economic Review (AER). 

Third, because it scales and automates. Automation is not only convenient. Like when you want to download data, process and create the same visualization and put it on your website any given Sunday. Automation is inevitable. Like when you have to gather daily updates from different outlets or work through thousands of .pdfs. 

Last but not least because of things you couldn't do w/o being an absolute guru (if at all) if wasn't for programming. Take  visualization. Go, check [these D3 Examples](https://d3js.org/). Now, try to do that in Excel. If you do these things in Excel it'd make you an absolute spreadsheet visualization Jedi, probably missing out on other time consuming skills to master. Moral of the story is, with decent, carpentry level programming skills -- that'd be the upfront investment -- you can already do so many spectular things while not really specializing and staying very flexible. 




## How to Read this Book? 

*Hacking for Social Sciences* is written based on the experience of helping students and seasoned researchers of different fields with their data management, processing and communication of results. A part of the book contains the information I wish I had when I started a PhD in economics. Part of the book is written years after said PhD was completed and with the hindsight of 10+ years in academia. Every page of the book is written with the belief that the future is OPEN and it is up to our generation of researchers to shape it. 

<!-- add ad from Germany "the future is OPEN" for open data and open source 
https://www.bildung-forschung.digital/files/191004_OA-Infoflyer_barrierefrei.pdf
-->

>If you came to ```r emo::ji("cherry")``` pick, you're welcome, too (but a bit early to the party though). This book will grow along the 2020 course 'Hacking for Social Science' and hopefully be finished in its first version by the end of the semester / year. Next up are chapters on the *Big Picture of Open Source Software for hacking data* and *Git version control*. 


# Stack - A Developer's Toolkit

Just like natural craftsmen, digital carpenters depend on their toolbox and their mastery of it. 
*Stack* is what developers call the choice of tools used in a particular project. Even though different flavors come down to personal preferences, there is a lot of common ground in *programming with data* stacks. Throughout this book, often a choice for one piece of software needs to be made in order to illustrate things. But please do understand these choices as examples and focus on the role of an item in the bigger picture. To help you with the big picture of which tool does what the following section will group common programming-with-data stack components. Also, note notice that not every role has to be filled in every project. 

<img src="images/dr_egghead_panics.jpg" width="700px">
<div class="caption">Aaaaaaah! Dr. Egghead is overwhelmed by the plethora of tools.</div>

Don't panic, Dr. Egghead! All these components are here to help you and there is plenty of choices...
Here are the components I use most often. Note, this is a personal choice which works for me. Obviously not ALL of these are components are used in every small project. *Git, R* and *R Studio* would be the very minimal version, I guess. 

```{r, eval=TRUE,message=FALSE, echo=FALSE}
library(kableExtra)
d <- data.frame(Component = c("Interpreter / Language", "IDE / Editor",
                              "Version Control","Project Management",
                              "Database", "'Virtual' Environments", "Website Hosting",
                              "Workflow Automation", "Continous Integration"),
                Choice = c("<a href='https://r-project.org'>R</a>, <a href='https://www.python.org/'>Python</a>, <a href=''>Javascript</a>","<a href='https://rstudio.com'>R Studio</a>,<a href='https://code.visualstudio.com/'>VS Code</a>, <a href='https://www.sublimetext.com/'>Sublime</a>",
                           "<a href='https://git-scm.com/'>Git</a>", "<a href='https://github.com/features/project-management/'>GitHub</a>, <a href='https://about.gitlab.com/solutions/project-management/'>GitLab</a>","<a href='https://www.postgresql.org/'>PostgreSQL</a>","<a href='https://www.docker.com/'>Docker</a>",
                           "<a href='https://netlify.com/'>Netlify</a>, <a href='https://pages.github.com/'>GitHub Pages</a>","<a href='https://airflow.apache.org/'>Apache Airflow</a>", "<a href='https://docs.gitlab.com/ee/ci/'>GitLab CI</a>"),
                stringsAsFactors = FALSE)
kable(d,"html",escape= FALSE)

```





## Languages: Compiled vs. Interpreted

In Statistical Computing -- at least in Social Sciences -- the interface between the researcher and the computation node is almost always an interpreted progamming language as opposed to a compiled one. Compiled languages like C++ require the developer to write source code and compile, i.e. translation of the source code into what a machine can work with happens *before* runtime. The result of the compilation process is a binary which is specific to the operating system. Hence you will need a version for Windows, one for OSX and one for Linux if you intend to reach a truly broad audience with your program. 







R and Python are the most popular OSS choices in hacking with data, <a href="httpsL">Julia</a> is an up and coming language with a much slimmer ecosystem which is focused on performance. 






## IDE

It's certainly possible to move a four person family into a new home by public transport, but it is not covenient. The same holds for (plain) text editors in programming. You can use them, but most people would prefer an Integrated Development Environment (IDE) just like they prefer to use a truck when they move. IDEs are tailored to the needs and idiosyncrasies of a language, some working with plugins and covering multiple languages. Others have a specific focus on a single language or a group of languages. There are several good choices for Programming With Data's favorite languages R and Python. 

Programming should be convenient and make the researcher feel comfortable. 
Even if you feel at home at a messy desk and wear sweatpants while you code, be advised that investing some time to set up your working evironment well is damn sure worth the investment.

For R, R Studio Desktop is the right choice for most people.
Also their server version is great: Install it on standard Virtual Machine or use a Docker Image to run R Studio Server. Users will be able to experience the R Studio Desktop look and feel in a browser without ever installing R or R Studio. 

For Python I love Visual Studio Code and also PyCharm as IDEs.
Honorable mention goes out the Sublime Text Editor which more lightweight and blazing fast. 


## Version Control: Git



### What is Git Version Control? 

Git is *not* Dropbox nor Google Drive. It does *not* sync automagically even if some Git GUI Tools suggest so. As opposed to that, a version control system allows to summarize a contribution across files and folders based on what this contribution is about. Assume you got a cool pointer from an econometrics professor at a conference and you incorporated her advice in your work. That advice is likely to affect different parts of your work: your text and your code. As opposed to syncing each of these files based on the time you saved them, version control creates a version when you decide to bundle things together and to commit the change. 

### Why Use Version Control in Research? 

>A version control based workflow fosters a path to your goals that rather consists of semantically relevant steps instead of random chunks based on time. 

Just in case the above paragraph about what version control is not enough of a justification to use git, let me be more blatant here: Naming your files like 
`final_version_your_name.R` or `final_final_correction_collaboratorX_20200114.R` 
is like given your WiFi a funny to communicate with your neighbors. Like `dont_park_the_car_in_the_frontyard` or `be_quiet_at_night`. This information is supposed to be sent in a message, not a file name. With version control it is immediately clear what the most current version is - no matter the file name. No room for interpretation. No need to start guessing about the delta between current or final and most recent. 

Also, you can easily try out different scenarios on different branches and merge them back together if you need to. Version control is a well established industry standard in software development. And it is relatively easy to adopt. With datasets growing in size and complexity in social sciences as well it is only natural to improve management of the code that processes these data. 

**Make Sure the Programmer's Workflow Section on Git in order to**

## Database: PostgreSQL

## Single Purpose Environments: Docker

Side Effect free working environment.


## Communication: Netlify

## Workflow Automation


# Programmers' Practices & Workflows

Just like most experienced engineers, seasoned software developers follow some kind of school or paradigm. Good programmers can even switch among approaches according to their current project's needs or depending on the team they are on. 

This section does not want to give a comprehensive overview over programming concepts nor compare approaches. And damn sure it does not mean to go to war over approach superiority. *Hacking for Social Scientists* rather cherry-picks suitable application-minded, low-barrier concepts that help social scientists professionalize their own programming. 


## Version Control

>No offense, if you are new to version control, it means you are new to programming.

Academia is probably the only place would allow you to dive into hacking at somewhat complex problems for several years w/o ever taking notice of version control. As a social scientist who rather collaborates in small groups and writes moderate amount of code, have you ever thought about how to collaborate with 100+ persons big software project? Or you to manage ten thousands of lines of code and beyond? Version control is just one of the reasons these things work. And it's been around for decade. Today, the decentralized version control system *git* has become the de facto standard of the open source community to manage code. 

### Git Basics

Git is a decentralized version control system which means all versions are stored on the local machines of every collaborator, not just on a remote server. This allows for a great workflow when it comes to putting versions together. 

But let's start at the very beginning. The git programm itself is a small console programm that is typically used through the console. You can install graphical user interfaces (GUI) on top of git but doing so does not really improve your understanding of the workflow. That's why the following examples straight up use the console -- even if you might choose a GUI tool like *Tortoise*, *SourceTree* or *Github Desktop* in the end. Also, many IDEs have git integration or offer plugins at least. 


```{r, eval=TRUE}
# INSERT PICTURE OF A BASH HERE
rnorm(10)
```

On the other hand you can navigate projects pretty well with about two hands full of git commands. Let us walk through the most important basic commands. 


- git clone: clone an entire repository from remote to your local disk. This keeps the address of the remote repository it's been cloned from. Use github.com's or gitlab.com's web site to create a repository. By cloning we do not only create a local copy but also set up the remote url. Nifty.

- git init: If you don't think about remote repositories and github.com accounts immediately, 
you can make any folder a git repository, i.e., put it under version control. *Beware*: Make sure not to initialize a repository in a repository!

- git add: add files to the staging area. The staging areas determines which changes will be committed when the next commit is triggered

- git commit -m 'some meaningful message': Create a new version, consisting of the changes made to the files in the staging area.

- git push: move all new commits to the remote repository (server). 

- git pull: get all new commits to the remote repository (server). 

- git checkout: Switch to another version / branch.

- git log: Show list of commit messages and commit identifiers. 

- git branch: Show available branches / current branch.


### Feature Branches - How to Use Git Efficiently in Teams

A very common and intuitive way to colloborate using git is to use feature branches:  












https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow
Eric Sink Version Control by Example
https://happygitwithr.com/


## Project Management 

## How to Document

## Development (Thinking Packages)

## Testing

Unit tests vs. regression tests.



## Deployment - Continous Integration

## Operations

## Collaboration



# Organize & Manage Data

## file based vs db

## SQL vs NoSQL



# Programming

## General Advice

## Scraping an Online Resource - Case Study

## Making the most of APIs - Case Study 

## Setup a Non-Interactive Batch Process /w tryCatch - Case Study 

## Cloud Computing - Case Study 

googleCloudStorageR
https://cloud.google.com/compute/docs/apis
https://cloudyr.github.io/googleComputeEngineR/

https://kubernetes.io/blog/2017/08/kubernetes-meets-high-performance/
https://www.hpcwire.com/2019/09/19/kubernetes-containers-and-hpc/

- containers on compute engine don't need kubernetes
https://cloud.google.com/compute/docs/containers/

- question for the google dude: Kubernetes for HPC
- *jobs that run to completion* 
- cost control? Slurm like ? you does it work in an organization, when everybody 
fires up their GCEs? 
- is there scheduler or do I have to fire up a scheduler VM
- https://github.com/kube-HPC/hkube
- https://en.paradigmadigital.com/dev/apache-airflow/
https://cloud.google.com/python/

## Online and Print - Case Study 

## Reproducible Reporting with RMarkdown and Knitr - Case Study 

## Using Docker as Sandbox - Case Study







